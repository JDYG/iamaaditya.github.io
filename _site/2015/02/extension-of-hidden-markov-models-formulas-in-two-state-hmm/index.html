<!DOCTYPE html>
<html>
  <head>
    <script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"> </script>
    <title>Extension of Hidden Markov Models &#8211; Formulas in two state HMM – Aaditya Prakash (Adi) – Random Musings of Computer Vision grad student</title>

        <meta charset="utf-8" />
    <meta content='text/html; charset=utf-8' http-equiv='Content-Type'>
    <meta http-equiv='X-UA-Compatible' content='IE=edge'>
    <meta name='viewport' content='width=device-width, initial-scale=1.0, maximum-scale=1.0'>

    
    <meta name="description" content="Extending the hidden markov models, where the current state is affected by past two states. This can be useful in simulation of games or in less sophisticated pricing models (more accurate would be an exponential decay of all past terms).
" />
    <meta property="og:description" content="Extending the hidden markov models, where the current state is affected by past two states. This can be useful in simulation of games or in less sophisticated pricing models (more accurate would be an exponential decay of all past terms).
" />
    
    <meta name="author" content="Aaditya Prakash (Adi)" />

    
    <meta property="og:title" content="Extension of Hidden Markov Models &#8211; Formulas in two state HMM" />
    <meta property="twitter:title" content="Extension of Hidden Markov Models &#8211; Formulas in two state HMM" />
    

    <!--[if lt IE 9]>
      <script src="http://html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->

    <link rel="stylesheet" type="text/css" href="/style.css" />
    <link rel="alternate" type="application/rss+xml" title="Aaditya Prakash (Adi) - Random Musings of Computer Vision grad student" href="/feed.xml" />

    <!-- Created with Jekyll Now - http://github.com/barryclark/jekyll-now -->
  </head>

  <body>
    <div class="wrapper-masthead">
      <div class="container">
        <header class="masthead clearfix">
          <a href="/" class="site-avatar"><img src="https://raw.githubusercontent.com/iamaaditya/iamaaditya.github.io/master/images/profile_image.png" /></a>

          <div class="site-info">
            <h1 class="site-name"><a href="/">Aaditya Prakash (Adi)</a></h1>
            <p class="site-description">Random Musings of Computer Vision grad student</p>
          </div>

          <nav>
            <a href="/">Blog</a>
            <a href="/notes">Notes</a>
            <a href="/about">About</a>
          </nav>
        </header>
      </div>
    </div>

    <div id="main" role="main" class="container">
      <article class="post">
  <h1>Extension of Hidden Markov Models &#8211; Formulas in two state HMM</h1>

  <div class="entry">
    <p>Extending the hidden markov models, where the current state is affected by past two states. This can be useful in simulation of games or in less sophisticated pricing models (more accurate would be an exponential decay of all past terms).</p>

<h2>Notations</h2>

<p>I have kept the notations close to as provided in Chapter 6 of &#8220;Speech and Language Processing&#8221;, Second Edition by Martin and Jurafsky.</p>

<p>\(\lambda\) Common term for all HMM parameters. All the probabilties<br>
will be conditioned to this term i.e \(P(&#8230;&#8230;|\lambda)\)</p>

<p>\(T\) denotes the total number of time steps</p>

<p>\(N\) denotes the total number of states</p>

<p>\(o_{t}\) denotes the observed variable (state) at time step t</p>

<p>\(q_{t}\) denotes the hidden variale (state) at time step t</p>

<h2>Formulas</h2>

<h3>Distribution of \(\alpha_{t}(i,j)\)</h3>

<p>\(\alpha_{t}(i,j)\) denotes the joint probability distribution of all observed variables until time \(t\) and current and the last states.</p>

<p>\[<br>
\alpha_{t}(i,j)=P(o_{1},o_{2},\dots,o_{t},q_{t-1}=i,q_{t}=j|\lambda)<br>
\]</p>

<p>Where \(\lambda\) is the given HMM parameters.</p>

<h3>Base case of \(\alpha_{t}(i,j)\)</h3>

<p>Consider the following notation:</p>

<p>\[<br>
a_{ij}=P(q_{t}=j|q_{t-1}=i)<br>
\]</p>

<p>\[<br>
a_{ijk}=P(q_{t+1}=k|q_{t}=j,q_{t-1}=i)<br>
\]</p>

<p>then base cases are &#8211;</p>

<p>\[<br>
\alpha_{1}(i=0,j)=a_{i=0,j}b_{j}(o_{1})<br>
\]</p>

<p>\[<br>
\alpha_{2}(i,j)=\alpha_{1}(0,j)a_{ij}b_{j}(o_{2})<br>
\]</p>

<p>It should be noted that if the second state (\(q_{2}\() is also allowed to be entry point, then it needs an additional base case of &#8212;</p>

<p>\[<br>
\alpha_{2}(i=0,j)=\sum_{i=1}^{N}\alpha_{1}(i=0,j)a_{ij}b_{j}(o_{2})<br>
\]</p>

<h3>Inductive step</h3>

<p>\[<br>
\alpha_{t}(j,k)=\sum_{i=1}^{N}\alpha_{t-1}(i,j)\times a_{ijk}\times b_{k}(o_{t})\text{ where, }3\leq t\leq T<br>
\]</p>

<h3>Termination step</h3>

<p>\[<br>
P(O|\lambda)=\sum_{i=1}^{N}\sum_{j=1}^{N}\alpha_{T}(i,j)\times a_{iF}\times a_{jF}\times a_{ijF}<br>
\]</p>

<h2>Estimated Expected Transitions</h2>

<h3>\(\xi_{t}\)</h3>

<p>\(\xi_{t}\) = Probability of being in state k at t+1, j at t and i at t-1</p>

<p>\[<br>
\xi_{t}=P(q_{t+1}=k,q_{t}=j,q_{t-1}=i|o_{1},\dots o_{T})=\frac{\alpha_{t}(i,j)\times\beta_{t+1}(j,k)\times a_{ijk}b_{k}(o_{t+1})}{\alpha(q_{f})}<br>
\]</p>

<h3>\(\gamma_{t}\)</h3>

<p>\(\gamma_{t}\) = Probability of being in state i at &#8216;t&#8217;, given all the obervations</p>

<p>\[<br>
\gamma_{t}=P(q_{t}=i|o_{1},\dots,o_{T})=\frac{\sum_{j}^{N}\alpha(j,i),\beta(j,i)}{\alpha(q_{f})}<br>
\]</p>

<p>where \(\alpha(q_{f})=P(o_{1},\dots,o_{T})\) (joint probability of all observed variables)</p>

<p>{*}Please note that for \(\gamma_{t}\) values, the \(i\) and \(j\) are interchanged in \(\alpha\) and \(\beta\) values, because I wanted to keep the input as \(q_{t}=i\), as provided in the problem, whereas convention in textbook is to denote \(i\) as antecedent to \(j\).</p>

<p><a title="Proofs for the two state hidden markov model" href="http://aaditya.info/research/hmm_two_states.pdf" target="_blank">Detailed proofs has been provided here</a></p>

  </div>

  <div class="date">
    Written on February 10, 2015
  </div>

  
<div class="comments">
	<div id="disqus_thread"></div>
	<script type="text/javascript">

	    var disqus_shortname = 'iamaaditya';

	    (function() {
	        var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
	        dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
	        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
	    })();

	</script>
	<noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
</div>

</article>

    </div>

    <div class="wrapper-footer">
      <div class="container">
        <footer class="footer">
          
<a href="mailto:aprakash [at] brandeis . edu"><i class="svg-icon email"></i></a>


<a href="https://github.com/barryclark/jekyll-now"><i class="svg-icon github"></i></a>

<a href="https://www.linkedin.com/in/http://in.linkedin.com/pub/aaditya-prakash/38/533/684"><i class="svg-icon linkedin"></i></a>

<a href="/feed.xml"><i class="svg-icon rss"></i></a>
<a href="https://www.twitter.com/jekyllrb"><i class="svg-icon twitter"></i></a>


<a href="https://plus.google.com//u/0/100303074762902184969?rel=author"><i class="svg-icon googleplus"></i></a>
        </footer>
      </div>
    </div>

    
	<!-- Google Analytics -->
	<script>
		(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
		(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
		m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
		})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

		ga('create', 'UA-70371377-1', 'auto');
		ga('send', 'pageview', {
		  'page': '/2015/02/extension-of-hidden-markov-models-formulas-in-two-state-hmm/',
		  'title': 'Extension of Hidden Markov Models &#8211; Formulas in two state HMM'
		});
	</script>
	<!-- End Google Analytics -->


  </body>
</html>
