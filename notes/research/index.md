---
title: Research
author: aaditya prakash
layout: page
dsq_thread_id:
  - 
---
## Sub-pages
 * [Convolutional Neural Network ]({{site.baseurl}}/notes/research/cnn/ ) 
 * [Transfer Learning]({{site.baseurl}}/notes/research/transfer/ )
 * [Visual Question Answering]( {{site.baseurl}}/notes/research/vqa/ )

## Burning thoughts 
 * Distributed representation (of features)
   > Can you learn X, Y, and detect X + Y ?
 * Can you tell the difference between an artificially generated image and a real image ? (Generative image models : <http://arxiv.org/abs/1506.05751> )
 * Saliency map and guided backpropagation <https://github.com/Lasagne/Recipes/blob/master/examples/Saliency%20Maps%20and%20Guided%20Backpropagation.ipynb>

## Papers reading currently
 * How transferable are features in deep neural networks? <http://arxiv.org/abs/1411.1792>
 * On Learning to Think: Algorithmic Information Theory for Novel Combinations of Reinforcement Learning Controllers and Recurrent Neural World Models <http://arxiv.org/abs/1511.09249>
 * GENERATING IMAGES FROM CAPTIONS WITH ATTENTION <http://arxiv.org/pdf/1511.02793v1.pdf>
 * Neural Program interpreters <http://www-personal.umich.edu/~reedscot/iclr_project.html>

## Recently read papers
 * Exploring Person Context and Local Scene Context for Object Detection <http://arxiv.org/pdf/1511.08177.pdf>
 * DeCAF: A Deep Convolutional Activation Feature for Generic Visual Recognition <http://arxiv.org/pdf/1310.1531v1.pdf>
 * On Learning Where To Look <http://www.cs.toronto.edu/~ranzato/publications/ranzato_arxiv14.pdf>

## Papers of interest
 * Human-level concept learning through probabilistic program induction <http://science.sciencemag.org/content/350/6266/1332.abstract>
 * Ask Me Anything: Dynamic Memory Networks for Natural Language Processing <http://arxiv.org/pdf/1506.07285v3.pdf>
 * Object detectors emerge in deep scene cnns <http://arxiv.org/pdf/1412.6856v2.pdf>
 * 21 hottest papers from ICCV 2015 <http://www.computervisionblog.com/2015/12/iccv-2015-twenty-one-hottest-research.html>
 * Memory Networks <http://arxiv.org/abs/1410.3916>

## Libraries currenty of interest
 * <https://github.com/karpathy/neuraltalk2>

## Articles 
 * Bayesian Methods for Neural Networks <http://www.cs.cmu.edu/afs/cs/academic/class/15782-f06/slides/bayesian.pdf>
 * Crash course in learning theory <https://blogs.princeton.edu/imabandit/2015/10/13/crash-course-on-learning-theory-part-1/>


## Notes

### Actor-Mimic: Deep Multitask and Transfer Reinforcement Learning <http://arxiv.org/abs/1511.06342>
    Instead of using a fresh network for each game, this team combined deep multitask reinforcement learning with deep-transfer learning to be able to use the same deep neural network across different types of games. This leads not only to a single instance that can succeed in multiple different games, but to one that also learns new games better and faster because of what it remembers about those other games. For example, it can learn a new tennis video game faster because it already gets the concept — the meaningful abstraction of hitting a ball with a paddle — from when it was playing Pong [Source](http://futureoflife.org/2015/12/29/the-top-a-i-breakthroughs-of-2015/)

### Bridge Correlational Neural Networks for Multilingual Multimodal Representation Learning <http://arxiv.org/abs/1510.03519>
    Joint embeddings to support the confluence of multiple meaningfully related mappings at once, across different modalities and different languages. As these embeddings get more sophisticated and detailed, they can become workhorses for more elaborate AI techniques

### Learning semantic relationships for better action retrieval in images <http://web.eecs.umich.edu/~jiadeng/paper/RamanathanEtAl_CVPR2015.pdf>
    Create a system that learns a meaningful schema of relationships between different types of actions from a set of photographs and a dictionary.

### DEEP MANIFOLD TRAVERSAL: CHANGING LABELS WITH CONVOLUTIONAL FEATURES <http://arxiv.org/pdf/1511.06421v1.pdf>
     Uses a dimensionality reduction of a deep net’s weights to form a surface of convolutional features that can simply be slid along to meaningfully, automatically, photorealistically alter particular aspects of photographs, e.g., changing people’s facial expressions or their ages, or colorizing photos.

### Expressing an Image Stream with a Sequence of Natural Sentences <http://www.cs.cmu.edu/~gunhee/publish/nips15_stream2text.pdf>
    **Video summarizing** Novel architecture called a coherent recurrent convolutional network, applying it to creating novel and fluid textual stories from sequences of images.

    
